# ðŸ”„ Data Unification Process - How Three Missions Became One Dataset

## Overview

The script `select_data.py` takes three completely different CSV formats from NASA and standardizes them into a single, unified format.

---

## The Challenge

Each NASA mission uses different column names and formats:

### ðŸ“¡ TESS (Transiting Exoplanet Survey Satellite)
- Column names: `pl_orbper`, `pl_trandurh`, `pl_trandep`, `pl_rade`, `pl_eqt`
- Disposition: "FP" = False Positive, others = Candidate
- IDs: TOI numbers (e.g., "TOI-509.01")

### ðŸª Kepler (Original Mission)
- Column names: `koi_period`, `koi_duration`, `koi_depth`, `koi_prad`, `koi_teq`
- Disposition: "CANDIDATE" or "FALSE POSITIVE" (as text)
- IDs: KOI numbers (e.g., "K00752.01")

### ðŸ”­ K2 (Kepler Extended Mission)
- Column names: `pl_orbper`, `pl_trandur`, `pl_trandep`, `pl_rade`, `pl_eqt`
- Disposition: "FALSE POSITIVE" or "CONFIRMED"/"CANDIDATE" (as text)
- IDs: EPIC or K2 designations (e.g., "K2-241 b")

---

## The Solution: Unified Format

All three are mapped to this single, standardized format:

```csv
type, id, name, disposition, period, duration, depth, prad, teq
```

### Column Mapping

| Unified Field | TESS Source | Kepler Source | K2 Source | Meaning |
|---------------|-------------|---------------|-----------|---------|
| **type** | "tess" | "kepler" | "k2" | Mission identifier |
| **id** | TIC ID (row[3]) | kepid | EPIC hostname | Star catalog ID |
| **name** | "TOI-XXX" | kepoi_name | pl_name | Planet designation |
| **disposition** | 0 or 1 | 0 or 1 | 0 or 1 | 0=FP, 1=Candidate |
| **period** | pl_orbper (row[14]) | koi_period | pl_orbper | Orbital period (days) |
| **duration** | pl_trandurh (row[15]) | koi_duration | pl_trandur | Transit duration (hours) |
| **depth** | pl_trandep (row[16]) | koi_depth | pl_trandep | Transit depth (ppm) |
| **prad** | pl_rade (row[17]) | koi_prad | pl_rade | Planet radius (Earth radii) |
| **teq** | pl_eqt (row[19]) | koi_teq | pl_eqt | Equilibrium temp (K) |

---

## The Code Walkthrough

### Step 1: Process TESS Data
```python
# Lines 17-34
disposition = 0 if row[6] == "FP" else 1  # Convert "FP" to 0, else 1
writer.writerow(["tess", tid, toi, disposition, pl_orbper, ...])
```
**Key insight:** TESS uses "FP" as a shorthand, so we convert it to 0/1.

### Step 2: Process Kepler Data
```python
# Lines 36-76
koi_score = 1 if koi_pdisposition == "CANDIDATE" else 0
writer.writerow(["kepler", kepid, kepoi_name, koi_score, koi_period, ...])
```
**Key insight:** Kepler spells out "CANDIDATE"/"FALSE POSITIVE", so we convert to 0/1.

### Step 3: Process K2 Data
```python
# Lines 78-125
k2_score = 0 if k2_disposition == "FALSE POSITIVE" else 1
# Skip rows with missing required fields
if any(f is None or f == "" for f in required_fields):
    continue
writer.writerow(["k2", k2_id, k2_name, k2_score, k2_period, ...])
```
**Key insight:** K2 has more missing data, so we filter out incomplete rows.

---

## The Result: dataset.csv

### Sample Output
```csv
type,id,name,disposition,period,duration,depth,prad,teq
tess,50365310,TOI-1000.01,0,2.1713484,2.0172196,656.8860989,5.8181633,3127.2040524
kepler,10797460,K00752.01,1,9.488036,2.9575,615.8,2.26,793.0
k2,EPIC-201274010,EPIC 201274010.01,1,7.7848,3.182,1320.0,4.19,1050.0
```

### Why This Works

1. **Physics is universal**: Period, depth, and radius mean the same thing regardless of which satellite measured them
2. **Standardized labels**: `disposition` is always 0 (FALSE POSITIVE) or 1 (CANDIDATE)
3. **Preserves origin**: The `type` column lets you track which mission data came from
4. **Clean data**: Missing values are handled appropriately for each mission

---

## What Gets Lost in Translation

### âš ï¸ Missing: Impact Parameter
- **Kepler** has it: `koi_impact`
- **TESS/K2** often don't
- **Decision**: Excluded from unified dataset to maintain consistency

### âš ï¸ Different Coverage
- Each mission has different:
  - Error bars (not included in unified dataset)
  - Vetting flags (intentionally excluded)
  - Additional parameters (stellar properties, etc.)

---

## Why This Unification is Smart

### âœ… Pros
1. **Allows multi-mission training**: Model learns from 17,589 samples instead of 9,564
2. **Reduces bias**: Model isn't overfit to one mission's quirks
3. **Better generalization**: Learns universal exoplanet physics
4. **Simpler code**: One data loader instead of three

### âš ï¸ Tradeoffs
1. **Lost some features**: Impact parameter and mission-specific metadata
2. **Slightly different data quality**: Each mission has different precision
3. **More missing values**: Unified dataset inherits gaps from all three

---

## For Your NASA Space Apps Presentation

> "We unified three NASA exoplanet datasetsâ€”Kepler, TESS, and K2â€”by mapping their different column formats to a standardized schema based on fundamental physics. This allowed our AI to learn from 17,589 exoplanets instead of being limited to a single mission, resulting in a more robust and generalizable classifier."

**This is sophisticated data engineering**, not just copying files. It shows you understand:
- Data heterogeneity challenges
- The importance of standardization
- Trade-offs in multi-source integration
- Domain knowledge (physics doesn't change between missions)

---

## Visual Summary

```
    TESS data           Kepler data          K2 data
   (7,704 rows)        (9,565 rows)        (4,005 rows)
        |                   |                    |
        |                   |                    |
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                    select_data.py
                   (Standardization)
                            |
                            â–¼
                     dataset.csv
                  (17,589 unified rows)
                            |
                            â–¼
                   LLM Training
                  (95.45% accuracy)
```

This is **real data science** in action! ðŸŽ“
